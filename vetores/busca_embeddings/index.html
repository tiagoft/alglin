<!DOCTYPE html>

<html data-bs-theme="light" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<link href="../../img/favicon.ico" rel="shortcut icon"/>
<title>Estudo de Caso: Embeddings - Álgebra Linear e Teoria da Informação</title>
<link href="../../css/bootstrap.min.css" rel="stylesheet"/>
<link href="../../css/fontawesome.min.css" rel="stylesheet"/>
<link href="../../css/brands.min.css" rel="stylesheet"/>
<link href="../../css/solid.min.css" rel="stylesheet"/>
<link href="../../css/v4-font-face.min.css" rel="stylesheet"/>
<link href="../../css/base.css" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" id="hljs-light" rel="stylesheet"/>
<link disabled="" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" id="hljs-dark" rel="stylesheet"/>
<link href="../../css/ansi-colours.css" rel="stylesheet"/>
<link href="../../css/jupyter-cells.css" rel="stylesheet"/>
<link href="../../css/pandas-dataframe.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
</head>
<body>
<div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
<div class="container">
<a class="navbar-brand" href="../..">Álgebra Linear e Teoria da Informação</a>
<!-- Expander button -->
<button aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-bs-target="#navbar-collapse" data-bs-toggle="collapse" type="button">
<span class="navbar-toggler-icon"></span>
</button>
<!-- Expanded navigation -->
<div class="navbar-collapse collapse" id="navbar-collapse">
<!-- Main navigation -->
<ul class="nav navbar-nav">
<li class="nav-item">
<a class="nav-link" href="../..">Home</a>
</li>
<li class="nav-item dropdown">
<a aria-current="page" aria-expanded="false" class="nav-link dropdown-toggle active" data-bs-toggle="dropdown" href="#" role="button">Vetores</a>
<ul class="dropdown-menu">
<li>
<a class="dropdown-item" href="../caminhando_pela_cidade/">Teoria: Uma caminhada por Chicago</a>
</li>
<li>
<a class="dropdown-item" href="../propriedades_soma_e_multiplicacao_escalar/">Teoria: Propriedades de vetores</a>
</li>
<li>
<a class="dropdown-item" href="../angulos/">Atividade: Ângulos e Distâncias</a>
</li>
<li>
<a class="dropdown-item" href="../numpy01/">Teoria: Vetores e Numpy</a>
</li>
<li>
<a class="dropdown-item" href="../confetes/">Estudo de Caso: Confetes Digitais</a>
</li>
<li>
<a class="dropdown-item" href="../projecoes/">Teoria: Projeções e produto interno</a>
</li>
<li>
<a aria-current="page" class="dropdown-item active" href="./">Estudo de Caso: Embeddings</a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<a aria-expanded="false" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button">Teoria da Informação</a>
<ul class="dropdown-menu">
<li>
<a class="dropdown-item" href="../../compressao/compressao_huffman/">Compressão Sem Perdas</a>
</li>
<li>
<a class="dropdown-item" href="../../compressao/compressao_sem_perdas_audio/">Prática: Compressão Sem Perdas em Áudio</a>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav ms-md-auto">
<li class="nav-item">
<a class="nav-link" data-bs-target="#mkdocs_search_modal" data-bs-toggle="modal" href="#">
<i class="fa fa-search"></i> Search
                            </a>
</li>
<li class="nav-item">
<a class="nav-link" href="../projecoes/" rel="prev">
<i class="fa fa-arrow-left"></i> Previous
                                </a>
</li>
<li class="nav-item">
<a class="nav-link" href="../../compressao/compressao_huffman/" rel="next">
                                    Next <i class="fa fa-arrow-right"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
<div class="container">
<div class="row">
<div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
<div class="navbar-header">
<button class="navbar-toggler collapsed" data-bs-target="#toc-collapse" data-bs-toggle="collapse" title="Table of Contents" type="button">
<span class="fa fa-angle-down"></span>
</button>
</div>
<div class="navbar-collapse collapse card bg-body-tertiary" id="toc-collapse">
<ul class="nav flex-column">
<li class="nav-item" data-bs-level="1"><a class="nav-link" href="#embeddings">Embeddings</a>
<ul class="nav flex-column">
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#exercicio-1-lembrar-se-da-teoria-de-alinhamento-de-vetores">Exercício 1: lembrar-se da teoria de alinhamento de vetores</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#exercicio-2-modelar-a-semelhanca-entre-vetores">Exercício 2: modelar a semelhança entre vetores</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#exercicio-3-implementar-a-busca-por-conteudo">Exercício 3: implementar a busca por conteúdo</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#exercicio-4-calcular-embeddings">Exercício 4: calcular embeddings</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#exercicio-5-gerar-um-banco-de-frases">Exercício 5: gerar um banco de frases</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#exercicio-6-avaliar-llms">Exercício 6: avaliar LLMs</a>
<ul class="nav flex-column">
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div></div>
<div class="col-md-9" role="main">
<h1 id="embeddings">Embeddings</h1>
<p>Nesta aula, utilizaremos os conceitos de vetores para implementar um sistema para detectar semelhança semântica de textos.</p>
<p>Você vai perceber que nesta aula específica não há "certo" ou "errado" -- o que há é um processo de aprendizado. Sendo o processo tão particular de cada um, é preciso que cada um seja responsável por si. O que gostaríamos nessa atividade é praticar o seguinte fluxo de pensamento:</p>
<div class="mermaid">

flowchart TD
    A[Entender a situação proposta: qual é o problema, e como sabemos que ele foi resolvido, isto é, quais são os critérios de aceitação] --&gt; B[Ligar a situação a um modelo matemático e suas variáveis] --&gt; C[Resolver o modelo matemático, possivelmente implementando um programa para isso] --&gt; D[Identificar, dentro do modelo resolvido e/ou dos resultados mostrados pelo programa, como a situação inicial foi resolvida]

</div>
<p>Por esse motivo, essa atividade não tem uma "rubrica" ou um "gabarito". Existem muitas soluções para cada um dos exercícios propostos. Porém, é importante que, para cada um deles, você explicitamente passe por todas as etapas do fluxo.</p>
<p>A quarta etapa é especialmente importante: como este é um trabalho aberto, isto é, que envolve o pensamento <em>divergente</em>, é esperado do aluno (e dos grupos de alunos) que o entendimento de cada etapa, e do que significa ter "resolvido" cada etapa, seja discutido pelo grupo de trabalho. Isso significa que fazer essa atividade pensando em "cumprir rapidamente etapas para entregar um resultado que será avaliado" não é produtivo. Ao invés disso, trata-se um trabalho importante pelo <em>vivenciar o processo</em>, e não pela entrega em si.</p>
<p>Dito isso, é claro que GPTs e IAs atuais resolvem todas as atividades. Não use GPTs e IAs para fazer o trabalho criativo para você neste contexto - até porque isso não faz nenhum sentido porque a atividade não recebe nota. Use essa oportunidade para identificar onde estão as <em>suas</em> dificuldades, e, ao superá-las, para exercitar o senso estético/poético de apreciar os resultados do programa que for fazendo.</p>
<h2 id="exercicio-1-lembrar-se-da-teoria-de-alinhamento-de-vetores">Exercício 1: lembrar-se da teoria de alinhamento de vetores</h2>
<p>A busca por conteúdo em bases de dados modernas usa um conceito chamado <em>embedding</em>. Um embedding é uma representação vetorial de um documento não-estruturado, isto é, é um vetor <span><span class="MathJax_Preview">$x_i \in \mathbb{R}^n$</span><script type="math/tex">x_i \in \mathbb{R}^n</script></span> que é único para cada ítem <span><span class="MathJax_Preview">$i$</span><script type="math/tex">i</script></span> em uma coleção. Uma característica de embeddings modernos é que, tipicamente, documentos semelhantes são mais alinhados, isto é, <span><span class="MathJax_Preview">$x_i$</span><script type="math/tex">x_i</script></span> e <span><span class="MathJax_Preview">$x_j$</span><script type="math/tex">x_j</script></span> são semelhantes se o cosseno do ângulo entre eles é grande.</p>
<p>Faça um desenho mostrando uma situação em <span><span class="MathJax_Preview">$\mathbb{R}^2$</span><script type="math/tex">\mathbb{R}^2</script></span> em que há oito embeddings diferentes. Escolha um deles como referência, e indique quais (dois ou três), dentre os restantes, são mais alinhados a ele.</p>
<h2 id="exercicio-2-modelar-a-semelhanca-entre-vetores">Exercício 2: modelar a semelhança entre vetores</h2>
<p>Suponha que temos dois vetores, <span><span class="MathJax_Preview">$x$</span><script type="math/tex">x</script></span> e <span><span class="MathJax_Preview">$y$</span><script type="math/tex">y</script></span> (<span><span class="MathJax_Preview">$x, y \in \mathbb{R}^n$</span><script type="math/tex">x, y \in \mathbb{R}^n</script></span>) . Escreva um processo matemático (isto é, uma equação), usando os conhecimentos que já temos, capaz de encontrar o cosseno do ângulo entre <span><span class="MathJax_Preview">$x$</span><script type="math/tex">x</script></span> e <span><span class="MathJax_Preview">$y$</span><script type="math/tex">y</script></span>.</p>
<h2 id="exercicio-3-implementar-a-busca-por-conteudo">Exercício 3: implementar a busca por conteúdo</h2>
<p>Suponha que temos uma lista em Python com <span><span class="MathJax_Preview">$m$</span><script type="math/tex">m</script></span> vetores <span><span class="MathJax_Preview">$x_i, i \in [1..m]$</span><script type="math/tex">x_i, i \in [1..m]</script></span>, representando embeddings de documentos em uma base de dados. </p>
<p>(a) Usando a equação que você definiu anteriormente, defina a função <code>alinhamento</code> com o cabeçalho abaixo, que calcula o alinhamento entre os vetores da sua base e um outro vetor, <span><span class="MathJax_Preview">$q$</span><script type="math/tex">q</script></span>, usado como referência;</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">alinhamento</span><span class="p">(</span><span class="n">x</span> <span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
                <span class="n">q</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
    <span class="k">pass</span>
</code></pre></div>
<p>(b) Mostre o funcionamento da sua função usando vetores que você deve definir manualmente. Se precisar, itere novamente no exercício anterior.</p>
<h2 id="exercicio-4-calcular-embeddings">Exercício 4: calcular embeddings</h2>
<p>Para calcular embeddings de <em>frases</em> ou de passagens curtas, tipicamente usamos transformers de sequência. Talvez você tenha que instalar a biblioteca <code>sentence_transformers</code> com: <code>pip install sentence_transformers</code>. Para usá-la, o exemplo típico é:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="c1"># Carregar o modelo na memória</span>
<span class="n">modelo</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">"all-MiniLM-L6-v2"</span><span class="p">)</span>

<span class="c1"># Sentenças para codificar</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"I am going to class."</span><span class="p">,</span>
    <span class="s2">"I am going to school."</span><span class="p">,</span>
    <span class="s2">"I like turtles."</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">query</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"I like fishes"</span><span class="p">]</span>

<span class="c1"># Gerar embeddings: x e q contém embeddings!</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</code></pre></div>
<p>Agora, use a função que você definiu no exercício anterior para verificar qual é a frase do dataset que mais se assemelha à query.</p>
<h2 id="exercicio-5-gerar-um-banco-de-frases">Exercício 5: gerar um banco de frases</h2>
<p>Repita o exercício 4, mas agora usando um banco de frases que você criou. O objetivo deste exercício é mostrar evidência de que o sistema realmente está funcionando como deveria.</p>
<h2 id="exercicio-6-avaliar-llms">Exercício 6: avaliar LLMs</h2>
<p>Hoje, existem LLMs, e eles são muito usados. Porém, é um fato que o conteúdo gerado por IA é facilmente indentificável porque tem traços de repetições de clichês e chavões. Vamos fazer um experimento para detectar se dois LLMs diferentes geram conteúdos que são repetições de si mesmos. Para isso:</p>
<ol>
<li>Escolha dois LLMs (ChatGPT, Grok, Gemini...).</li>
<li>Para cada um deles, use o prompt para gerar 20 frases dentro do tema à sua escolha (dica: peça para já gerar as frases na forma de uma lista de strings em Python, por exemplo: "gere 20 frases que poderiam ser ditas por um supervilão de um filme pastelão. Formate as frases como uma lista de strings de Python"). Temos então dois conjuntos de frases.</li>
<li>Após, calcule a semelhança entre cada frase gerada e todas as outras que foram geradas. Queremos aqui duas quantidades: a semelhança média entre uma frase e as outras frases geradas pelo mesmo LLM, e a semelhança média entre uma frase e as frases geradas pelo outro LLM.</li>
<li>Os números que você encontrou permitem dizer que cada LLM <em>tende</em> a gerar frases com um determinado estilo, e que esse estilo é distinto para cada LLM?</li>
</ol></div>
</div>
</div>
<footer class="col-md-12">
<hr/>
<p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
</footer>
<script src="../../js/bootstrap.bundle.min.js"></script>
<script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
<script src="../../js/base.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script src="https://unpkg.com/mermaid@10.4.0/dist/mermaid.min.js"></script>
<script src="../../search/main.js"></script>
<div aria-hidden="true" aria-labelledby="searchModalLabel" class="modal" id="mkdocs_search_modal" role="dialog" tabindex="-1">
<div class="modal-dialog modal-lg">
<div class="modal-content">
<div class="modal-header">
<h4 class="modal-title" id="searchModalLabel">Search</h4>
<button aria-label="Close" class="btn-close" data-bs-dismiss="modal" type="button"></button>
</div>
<div class="modal-body">
<p>From here you can search these documents. Enter your search terms below.</p>
<form>
<div class="form-group">
<input class="form-control" id="mkdocs-search-query" placeholder="Search..." title="Type search term here" type="search"/>
</div>
</form>
<div data-no-results-text="No results found" id="mkdocs-search-results"></div>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div><div aria-hidden="true" aria-labelledby="keyboardModalLabel" class="modal" id="mkdocs_keyboard_modal" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
<button aria-label="Close" class="btn-close" data-bs-dismiss="modal" type="button"></button>
</div>
<div class="modal-body">
<table class="table">
<thead>
<tr>
<th style="width: 20%;">Keys</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td class="help shortcut"><kbd>?</kbd></td>
<td>Open this help</td>
</tr>
<tr>
<td class="next shortcut"><kbd>n</kbd></td>
<td>Next page</td>
</tr>
<tr>
<td class="prev shortcut"><kbd>p</kbd></td>
<td>Previous page</td>
</tr>
<tr>
<td class="search shortcut"><kbd>s</kbd></td>
<td>Search</td>
</tr>
</tbody>
</table>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div>
<script>mermaid.initialize({});</script></body>
</html>
